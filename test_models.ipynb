{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\miniconda3\\envs\\torch_env\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import mne\n",
    "import scipy.signal as sg\n",
    "from dataset import TimeSeriesDataset\n",
    "from models import Model_CNN_LSTM, MultiResolutionModel, MultiResolutionLSTMFFT\n",
    "import mlflow.pytorch\n",
    "import torchmetrics\n",
    "from losses import FocalLoss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import io\n",
    "from torchview import draw_graph\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_fpath = \"./DatabaseSubjects/\"\n",
    "data_files = glob.glob(files_fpath + \"/*.edf\")\n",
    "anno_files = glob.glob(files_fpath + \"/HypnogramAASM_*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Separete into train and test files\n",
    "train_data_files, test_data_files, train_anno_files, test_anno_files = train_test_split(data_files, anno_files, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject17.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\miniconda3\\envs\\torch_env\\lib\\site-packages\\mne\\io\\edf\\edf.py:782: RuntimeWarning: All-NaN axis encountered\n",
      "  value = np.nanmax([_prefilter_float(x) for x in values])\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\miniconda3\\envs\\torch_env\\lib\\site-packages\\mne\\io\\edf\\edf.py:784: RuntimeWarning: All-NaN axis encountered\n",
      "  value = np.nanmin([_prefilter_float(x) for x in values])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 5981999  =      0.000 ... 29909.995 secs...\n",
      "Signal shape: (6, 5982000)\n",
      "Signal shape: (2, 5982000)\n",
      "Data shape: (8, 5982000), fs: 200, segmentation size: 1000, annotations: 5982\n",
      "Data shape after padding: (5983000, 8), annotations: 5982\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 6025999  =      0.000 ... 30129.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 6026000)\n",
      "Signal shape: (2, 6026000)\n",
      "Data shape: (8, 6026000), fs: 200, segmentation size: 1000, annotations: 6026\n",
      "Data shape after padding: (6027000, 8), annotations: 6026\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject2.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5909999  =      0.000 ... 29549.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 5910000)\n",
      "Signal shape: (2, 5910000)\n",
      "Data shape: (8, 5910000), fs: 200, segmentation size: 1000, annotations: 5910\n",
      "Data shape after padding: (5911000, 8), annotations: 5910\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject12.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5767999  =      0.000 ... 28839.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 5768000)\n",
      "Signal shape: (2, 5768000)\n",
      "Data shape: (8, 5768000), fs: 200, segmentation size: 1000, annotations: 5768\n",
      "Data shape after padding: (5769000, 8), annotations: 5768\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject8.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5819999  =      0.000 ... 29099.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 5820000)\n",
      "Signal shape: (2, 5820000)\n",
      "Data shape: (8, 5820000), fs: 200, segmentation size: 1000, annotations: 5820\n",
      "Data shape after padding: (5821000, 8), annotations: 5820\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject6.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5983999  =      0.000 ... 29919.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 5984000)\n",
      "Signal shape: (2, 5984000)\n",
      "Data shape: (8, 5984000), fs: 200, segmentation size: 1000, annotations: 5984\n",
      "Data shape after padding: (5985000, 8), annotations: 5984\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject3.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 6051999  =      0.000 ... 30259.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 6052000)\n",
      "Signal shape: (2, 6052000)\n",
      "Data shape: (8, 6052000), fs: 200, segmentation size: 1000, annotations: 6052\n",
      "Data shape after padding: (6053000, 8), annotations: 6052\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 6049999  =      0.000 ... 30249.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 6050000)\n",
      "Signal shape: (2, 6050000)\n",
      "Data shape: (8, 6050000), fs: 200, segmentation size: 1000, annotations: 6050\n",
      "Data shape after padding: (6051000, 8), annotations: 6050\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject18.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 6127999  =      0.000 ... 30639.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 6128000)\n",
      "Signal shape: (2, 6128000)\n",
      "Data shape: (8, 6128000), fs: 200, segmentation size: 1000, annotations: 6128\n",
      "Data shape after padding: (6129000, 8), annotations: 6128\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject9.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 6703999  =      0.000 ... 33519.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 6704000)\n",
      "Signal shape: (2, 6704000)\n",
      "Data shape: (8, 6704000), fs: 200, segmentation size: 1000, annotations: 6704\n",
      "Data shape after padding: (6705000, 8), annotations: 6704\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 6667999  =      0.000 ... 33339.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 6668000)\n",
      "Signal shape: (2, 6668000)\n",
      "Data shape: (8, 6668000), fs: 200, segmentation size: 1000, annotations: 6668\n",
      "Data shape after padding: (6669000, 8), annotations: 6668\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject20.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 6869999  =      0.000 ... 34349.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 6870000)\n",
      "Signal shape: (2, 6870000)\n",
      "Data shape: (8, 6870000), fs: 200, segmentation size: 1000, annotations: 6870\n",
      "Data shape after padding: (6871000, 8), annotations: 6870\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject16.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5805999  =      0.000 ... 29029.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 5806000)\n",
      "Signal shape: (2, 5806000)\n",
      "Data shape: (8, 5806000), fs: 200, segmentation size: 1000, annotations: 5806\n",
      "Data shape after padding: (5807000, 8), annotations: 5806\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject19.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 6201999  =      0.000 ... 31009.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 6202000)\n",
      "Signal shape: (2, 6202000)\n",
      "Data shape: (8, 6202000), fs: 200, segmentation size: 1000, annotations: 6202\n",
      "Data shape after padding: (6203000, 8), annotations: 6202\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject4.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 6317999  =      0.000 ... 31589.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 6318000)\n",
      "Signal shape: (2, 6318000)\n",
      "Data shape: (8, 6318000), fs: 200, segmentation size: 1000, annotations: 6318\n",
      "Data shape after padding: (6319000, 8), annotations: 6318\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject15.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5039999  =      0.000 ... 25199.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 5040000)\n",
      "Signal shape: (2, 5040000)\n",
      "Data shape: (8, 5040000), fs: 200, segmentation size: 1000, annotations: 5040\n",
      "Data shape after padding: (5041000, 8), annotations: 5040\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5767999  =      0.000 ... 28839.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 5768000)\n",
      "Signal shape: (2, 5768000)\n",
      "Data shape: (8, 5768000), fs: 200, segmentation size: 1000, annotations: 5768\n",
      "Data shape after padding: (5769000, 8), annotations: 5768\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject7.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 6071999  =      0.000 ... 30359.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 6072000)\n",
      "Signal shape: (2, 6072000)\n",
      "Data shape: (8, 6072000), fs: 200, segmentation size: 1000, annotations: 6072\n",
      "Data shape after padding: (6073000, 8), annotations: 6072\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject5.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 6257999  =      0.000 ... 31289.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 6258000)\n",
      "Signal shape: (2, 6258000)\n",
      "Data shape: (8, 6258000), fs: 200, segmentation size: 1000, annotations: 6258\n",
      "Data shape after padding: (6259000, 8), annotations: 6258\n",
      "Extracting EDF parameters from c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\DatabaseSubjects\\subject10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 6195999  =      0.000 ... 30979.995 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different highpass filters. Highest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n",
      "c:\\Users\\rafar\\Documents\\2024\\Disciplina - Machine Learning Para séries Temporais\\Trabalho1\\dataset.py:49: RuntimeWarning: Channels contain different lowpass filters. Lowest filter setting will be stored.\n",
      "  data = mne.io.read_raw_edf(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (6, 6196000)\n",
      "Signal shape: (2, 6196000)\n",
      "Data shape: (8, 6196000), fs: 200, segmentation size: 1000, annotations: 6196\n",
      "Data shape after padding: (6197000, 8), annotations: 6196\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TimeSeriesDataset(train_data_files, train_anno_files, n_past=0, segmentation_size_sec=5)\n",
    "test_dataset = TimeSeriesDataset(test_data_files, test_anno_files, n_past=0, segmentation_size_sec=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_alias = {\n",
    "    0: 'dont_care',\n",
    "    1: 'N3',\n",
    "    2: 'N2',\n",
    "    3: 'N1',\n",
    "    4: 'REM',\n",
    "    5: 'A',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `labels` is a list or NumPy array containing the class labels for all samples\n",
    "class_counts = np.bincount(train_dataset.annotations)  # Count occurrences of each class\n",
    "class_weights = 1.0 / class_counts  # Inverse of frequencies\n",
    "class_weights[0] = 0\n",
    "\n",
    "# Assign weights to each sample based on its class\n",
    "sample_weights = np.array([class_weights[label] for label in train_dataset.annotations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "\n",
    "# Convert weights to a tensor\n",
    "sample_weights = torch.DoubleTensor(sample_weights)\n",
    "\n",
    "# Create the sampler\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),  # Total samples to draw per epoch\n",
    "    replacement=True  # Allow replacement for oversampling,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\miniconda3\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMFormerFFT(\n",
       "  (fft_lstm_block): FFTLSTMBlock(\n",
       "    (fft): SlidingFFT()\n",
       "    (conv1): Conv1d(1608, 512, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=same)\n",
       "    (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (lstm): LSTM(1024, 512, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "    (conv3): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4): Conv1d(512, 256, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    (dropout1): Dropout(p=0.2, inplace=False)\n",
       "    (dropout2): Dropout(p=0.2, inplace=False)\n",
       "    (dropout3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (conv0): Conv1d(8, 32, kernel_size=(10,), stride=(1,), padding=same)\n",
       "  (bn0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (lstmformer1): LstmFormerBlock(\n",
       "    (conv1): Conv1d(32, 64, kernel_size=(10,), stride=(1,), padding=same)\n",
       "    (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (lstm): LSTM(64, 64, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "    (conv2): Conv1d(128, 64, kernel_size=(1,), stride=(1,), padding=same)\n",
       "  )\n",
       "  (lstmformer2): LstmFormerBlock(\n",
       "    (conv1): Conv1d(64, 128, kernel_size=(10,), stride=(1,), padding=same)\n",
       "    (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (lstm): LSTM(128, 128, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "    (conv2): Conv1d(256, 128, kernel_size=(1,), stride=(1,), padding=same)\n",
       "  )\n",
       "  (lstmformer3): LstmFormerBlock(\n",
       "    (conv1): Conv1d(128, 256, kernel_size=(10,), stride=(1,), padding=same)\n",
       "    (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (lstm): LSTM(256, 256, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,), padding=same)\n",
       "  )\n",
       "  (lstmformer4): LstmFormerBlock(\n",
       "    (conv1): Conv1d(256, 512, kernel_size=(10,), stride=(1,), padding=same)\n",
       "    (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (lstm): LSTM(512, 512, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "    (conv2): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), padding=same)\n",
       "  )\n",
       "  (dec_conv4): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "  (dec_downsample4): Identity()\n",
       "  (dec_conv3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "  (dec_downsample3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dec_conv2): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "  (dec_downsample2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dec_conv1): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "  (dec_downsample1): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv1d(1280, 256, kernel_size=(1,), stride=(1,))\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (cross_attention1): CrossAttentionResidualBlock(\n",
       "    (cross_attention): CrossAttentionTimeSeriesModel(\n",
       "      (embed_1): TimeSeriesEmbedding(\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (embed_2): TimeSeriesEmbedding(\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (cross_attention): CrossAttentionLayer(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cross_attention2): CrossAttentionResidualBlock(\n",
       "    (cross_attention): CrossAttentionTimeSeriesModel(\n",
       "      (embed_1): TimeSeriesEmbedding(\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (embed_2): TimeSeriesEmbedding(\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (cross_attention): CrossAttentionLayer(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cross_attention3): CrossAttentionResidualBlock(\n",
       "    (cross_attention): CrossAttentionTimeSeriesModel(\n",
       "      (embed_1): TimeSeriesEmbedding(\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (embed_2): TimeSeriesEmbedding(\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (cross_attention): CrossAttentionLayer(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cross_attention4): CrossAttentionResidualBlock(\n",
       "    (cross_attention): CrossAttentionTimeSeriesModel(\n",
       "      (embed_1): TimeSeriesEmbedding(\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (embed_2): TimeSeriesEmbedding(\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (cross_attention): CrossAttentionLayer(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cross_attention5): CrossAttentionResidualBlock(\n",
       "    (cross_attention): CrossAttentionTimeSeriesModel(\n",
       "      (embed_1): TimeSeriesEmbedding(\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (embed_2): TimeSeriesEmbedding(\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (cross_attention): CrossAttentionLayer(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(256, 64, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model initialization\n",
    "#model = Model_CNN_LSTM(n_sensors=8, num_classes=6, fs=200, time_frame=5,)\n",
    "#model = MultiResolutionModel(n_sensors=8, num_classes=6, fs=200, time_frame=5,)\n",
    "model = MultiResolutionLSTMFFT(num_channels=8, num_classes=6, fs=200, time_frame=5,)\n",
    "num_classes=6\n",
    "criterion = FocalLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = torchmetrics.Accuracy(num_classes=num_classes, average='none', task='multiclass').to(device)\n",
    "precision = torchmetrics.Precision(num_classes=num_classes, average='none', task='multiclass').to(device)\n",
    "recall = torchmetrics.Recall(num_classes=num_classes, average='none', task='multiclass').to(device)\n",
    "f1 = torchmetrics.F1Score(num_classes=num_classes, average='none', task='multiclass').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_and_log(predictions, labels, num_classes, exclude_label=0):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix for the predictions, excluding the specified label, \n",
    "    and logs it to MLflow using mlflow.log_image.\n",
    "    \n",
    "    Args:\n",
    "    - predictions (torch.Tensor or np.ndarray): The model's predicted class labels.\n",
    "    - labels (torch.Tensor or np.ndarray): The true class labels.\n",
    "    - num_classes (int): The total number of classes (excluding the label to be ignored).\n",
    "    - exclude_label (int): The class label to exclude (default: 0).\n",
    "    \"\"\"\n",
    "    # Filter out the samples with the 'exclude_label'\n",
    "    mask = labels != exclude_label\n",
    "    filtered_preds = predictions[mask]\n",
    "    filtered_labels = labels[mask]\n",
    "\n",
    "    # Debugging: Check the types and shapes\n",
    "    print(f\"Type of filtered_preds: {type(filtered_preds)}\")\n",
    "    print(f\"Shape of filtered_preds: {filtered_preds.shape if isinstance(filtered_preds, torch.Tensor) else 'Not a tensor'}\")\n",
    "    print(f\"Type of filtered_labels: {type(filtered_labels)}\")\n",
    "    print(f\"Shape of filtered_labels: {filtered_labels.shape if isinstance(filtered_labels, torch.Tensor) else 'Not a tensor'}\")\n",
    "\n",
    "    # Convert tensors to NumPy arrays if they are still tensors\n",
    "    if isinstance(filtered_preds, torch.Tensor):\n",
    "        filtered_preds = filtered_preds.cpu().numpy()\n",
    "    if isinstance(filtered_labels, torch.Tensor):\n",
    "        filtered_labels = filtered_labels.cpu().numpy()\n",
    "\n",
    "    # Debugging: Check if they are now NumPy arrays\n",
    "    print(f\"Type of filtered_preds after conversion: {type(filtered_preds)}\")\n",
    "    print(f\"Type of filtered_labels after conversion: {type(filtered_labels)}\")\n",
    "\n",
    "    # Ensure both are arrays and not scalars\n",
    "    filtered_preds = np.asarray(filtered_preds)\n",
    "    filtered_labels = np.asarray(filtered_labels)\n",
    "\n",
    "    # Ensure filtered_labels and filtered_preds are not empty and are array-like\n",
    "    if filtered_preds.ndim == 0 or filtered_labels.ndim == 0:\n",
    "        raise ValueError(\"The predictions and labels must be array-like and cannot be scalar.\")\n",
    "    \n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(filtered_labels, filtered_preds, labels=range(1, num_classes))\n",
    "    \n",
    "    # Create a ConfusionMatrixDisplay object\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(1, num_classes))\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    disp.plot(cmap='Blues', values_format='d', ax=ax)\n",
    "    plt.title(f'Confusion Matrix (Excluding Label {exclude_label})')\n",
    "    \n",
    "    # Save the plot to a BytesIO buffer\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Log the image to MLflow\n",
    "    mlflow.log_image(buf, \"confusion_matrix.png\")\n",
    "    \n",
    "    # Close the plot to free memory\n",
    "    plt.close(fig)\n",
    "\n",
    "def log_model_graph_as_svg(model, train_loader):\n",
    "    \"\"\"\n",
    "    Generates and logs the model graph as an SVG artifact in MLflow.\n",
    "    \n",
    "    Args:\n",
    "    - model (nn.Module): The trained model.\n",
    "    - train_loader (DataLoader): The DataLoader to get a batch of input data.\n",
    "    \"\"\"\n",
    "    # Generate the model graph visualization\n",
    "    input_size = next(iter(train_loader))[0].shape  # Get the shape of the input\n",
    "    \n",
    "    # Use the draw_graph function with basic parameters\n",
    "    try:\n",
    "        model_graph = draw_graph(\n",
    "            model, \n",
    "            input_size=input_size, \n",
    "            depth=2,  # Use a smaller depth for simplicity\n",
    "            device='cpu',  # Adjust device if needed\n",
    "            show_shapes=True,  # Show tensor shapes\n",
    "            save_graph=True,  # Don't save yet, just visualize\n",
    "            filename='model_graph.png',  # We will handle the output file path later\n",
    "            directory='./',  # Directory for saving graph\n",
    "        )\n",
    "\n",
    "        # Check if the model graph is valid\n",
    "        if model_graph is None or not model_graph.visual_graph:\n",
    "            raise ValueError(\"Failed to generate model graph visualization. Please check the input model.\")\n",
    "        \n",
    "        print(\"Graph visualization generated successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to generate model graph: {e}\")\n",
    "    \n",
    "    # Log the generated SVG artifact to MLflow\n",
    "    try:\n",
    "        mlflow.log_artifact('./model_graph.png.png', \"model_graph.png\")\n",
    "        print(\"Model graph has been logged as an artifact in MLflow.\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to log SVG artifact to MLflow: {e}\")\n",
    "    \n",
    "\n",
    "def compute_loss(outputs, labels, criterion):\n",
    "    # Mask to exclude label 0\n",
    "    non_zero_mask = labels != 0\n",
    "    \n",
    "    # Apply the mask to outputs and labels (this effectively ignores label 0)\n",
    "    masked_labels = labels[non_zero_mask]\n",
    "    masked_outputs = outputs[non_zero_mask]\n",
    "    \n",
    "    # If there are no valid labels (i.e., all labels are 0), return a loss of 0\n",
    "    if masked_labels.size(0) == 0:\n",
    "        return torch.tensor(0.0, device=outputs.device)\n",
    "\n",
    "    # Calculate the loss for the masked labels\n",
    "    loss = criterion(masked_outputs, masked_labels)\n",
    "    return loss\n",
    "\n",
    "# Training loop for one epoch\n",
    "# Training loop for one epoch\n",
    "def train_epoch(model, dataloader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm.tqdm(dataloader)\n",
    "    for iteration, (X, y) in enumerate(pbar):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        # Apply softmax\n",
    "        output = torch.nn.Softmax(-1)(output)\n",
    "        loss = compute_loss(output, y, criterion)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Log the loss for this iteration\n",
    "        mlflow.log_metric(\"train_loss\", loss.item(), step=epoch * len(dataloader) + iteration)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_description(f\"Loss: {loss.item()}\")\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Validation loop (including metrics calculation)\n",
    "def validate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X)\n",
    "            loss = compute_loss(output, y, criterion)\n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(output.argmax(1).cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "            # Update TorchMetrics with predictions and true labels\n",
    "            accuracy.update(output, y)\n",
    "            precision.update(output, y)\n",
    "            recall.update(output, y)\n",
    "            f1.update(output, y)\n",
    "\n",
    "    # Calculate final metrics from TorchMetrics\n",
    "    acc = accuracy.compute()\n",
    "    prec = precision.compute()\n",
    "    rec = recall.compute()\n",
    "    f1_score = f1.compute()\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    #cm = confusion_matrix(all_labels, all_preds, num_classes)\n",
    "\n",
    "    # Get class names using the alias dictionary\n",
    "    class_names = [class_name_alias[i] for i in range(num_classes)]\n",
    "    \n",
    "    # Plot confusion matrix and save it to a file\n",
    "    #plot_confusion_matrix_and_log(all_preds, all_labels, num_classes=num_classes, exclude_label=0)\n",
    "\n",
    "    # Log confusion matrix image to MLflow\n",
    "    #mlflow.log_artifact('confusion_matrix.png')\n",
    "\n",
    "    # Reset metrics after each validation step\n",
    "    accuracy.reset()\n",
    "    precision.reset()\n",
    "    recall.reset()\n",
    "    f1.reset()\n",
    "\n",
    "    # Return loss, accuracy, and per-class metrics\n",
    "    accuracy_value = acc.mean().item()  # mean accuracy across all classes\n",
    "    return total_loss / len(dataloader), accuracy_value, prec.cpu().numpy(), rec.cpu().numpy(), f1_score.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafar\\miniconda3\\envs\\torch_env\\lib\\site-packages\\torch\\_tensor.py:1279: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\Convolution.cpp:896.)\n",
      "  ret = func(*args, **kwargs)\n",
      "\n",
      "(process:32212): Pango-WARNING **: 16:44:07.733: couldn't load font \"Linux libertine Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph visualization generated successfully.\n",
      "Model graph has been logged as an artifact in MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0354379415512085: 100%|██████████| 6083/6083 [27:49<00:00,  3.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Train Loss: 0.9074, Val Loss: 0.9605, Val Acc: 0.4996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7642558813095093: 100%|██████████| 6083/6083 [25:42<00:00,  3.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/8, Train Loss: 0.7923, Val Loss: 1.1332, Val Acc: 0.5130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7611589431762695: 100%|██████████| 6083/6083 [28:06<00:00,  3.61it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/8, Train Loss: 0.7677, Val Loss: 1.3026, Val Acc: 0.5112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8497283458709717: 100%|██████████| 6083/6083 [27:51<00:00,  3.64it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/8, Train Loss: 0.7529, Val Loss: 1.3030, Val Acc: 0.5259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8201395869255066: 100%|██████████| 6083/6083 [28:09<00:00,  3.60it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/8, Train Loss: 0.7409, Val Loss: 1.5525, Val Acc: 0.5034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6776416897773743: 100%|██████████| 6083/6083 [28:46<00:00,  3.52it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/8, Train Loss: 0.7372, Val Loss: 1.2664, Val Acc: 0.5272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6147096157073975: 100%|██████████| 6083/6083 [31:36<00:00,  3.21it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8, Train Loss: 0.7298, Val Loss: 1.8490, Val Acc: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.70076584815979: 100%|██████████| 6083/6083 [28:14<00:00,  3.59it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/8, Train Loss: 0.7265, Val Loss: 1.2573, Val Acc: 0.5176\n",
      "Training complete and metrics logged!\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"complete_experiment2\"\n",
    "num_epochs = 8\n",
    "\n",
    "\n",
    "# Set or create the experiment\n",
    "mlflow.set_tracking_uri(r\"sqlite:///C:\\Users\\rafar\\Documents\\mlflow\\mlflow.db\")\n",
    "mlflow.set_experiment(experiment_name)\n",
    "#\n",
    "## Start the MLflow run\n",
    "mlflow.start_run()\n",
    "log_model_graph_as_svg(model, train_loader)\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    # Train the model for one epoch\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, epoch)\n",
    "    \n",
    "    # Validate the model and get metrics\n",
    "    val_loss, val_acc, precision_per_class, recall_per_class, f1_per_class = validate(model, test_loader, criterion)\n",
    "    \n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "    mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "    mlflow.log_metric(\"val_accuracy\", val_acc, step=epoch)\n",
    "    \n",
    "    # Log per-class metrics for precision, recall, and F1 score\n",
    "    for class_id in range(num_classes):\n",
    "        if class_id == 0:\n",
    "            continue\n",
    "        class_name = class_name_alias[class_id]\n",
    "        mlflow.log_metric(f\"precision_class_{class_name}\", precision_per_class[class_id], step=epoch)\n",
    "        mlflow.log_metric(f\"recall_class_{class_name}\", recall_per_class[class_id], step=epoch)\n",
    "        mlflow.log_metric(f\"f1_class_{class_name}\", f1_per_class[class_id], step=epoch)\n",
    "    \n",
    "    # Print the progress for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# End the MLflow run\n",
    "mlflow.end_run()\n",
    "\n",
    "print(\"Training complete and metrics logged!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
